{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity\n",
    "\n",
    "The first step in determing the validity of the message is to compare it to a database of known hoax messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `messages.csv` file contains 82 known hoax WhatsApp messages that we collected over the course of the 2 day hackathon.  We don't need volume of data for this step as we are simply going to compare incoming messages for similarity against a known corpus of hoaxes.  Over time this corpus will grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/messages.csv', header=None)\n",
    "df.columns = ['quote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1st time in the world history a 101year old la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\nCarte Blanche: E-toll. Forward on to as many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40 Year Old Man Is Diagnosed With Eye Cancer B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>\\nHi guys, Just want to tell you about this cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ISIS recruiter, traitor and runaway criminal Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>\\nWhatsApp is going to cost us money soon. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>\\nPlease note that there won't be electricity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>\\nWhatsapp is shutting down on 28th jan Messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAKISTAN: MAN SENTENCED TO DEATH FOR FARTING I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Whatsapp celebrating 10 years by giving exciti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quote\n",
       "32  1st time in the world history a 101year old la...\n",
       "66  \\nCarte Blanche: E-toll. Forward on to as many...\n",
       "16  40 Year Old Man Is Diagnosed With Eye Cancer B...\n",
       "75  \\nHi guys, Just want to tell you about this cr...\n",
       "14  ISIS recruiter, traitor and runaway criminal Z...\n",
       "81  \\nWhatsApp is going to cost us money soon. The...\n",
       "53  \\nPlease note that there won't be electricity ...\n",
       "57  \\nWhatsapp is shutting down on 28th jan Messag...\n",
       "9   PAKISTAN: MAN SENTENCED TO DEATH FOR FARTING I...\n",
       "45  Whatsapp celebrating 10 years by giving exciti..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "# Transform all of our known documents into vector space\n",
    "tfidf_matrix = tfidf.fit_transform(df['quote'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a helper function to return similarity of a given string\n",
    "def getSimilarity(text_string):\n",
    "    # convert test into vector matrix\n",
    "    test_matrix = tfidf.transform([text_string])\n",
    "    # Create array of cosine similarities\n",
    "    sim = (tfidf_matrix * test_matrix.T).A\n",
    "    # Print out the similarity score of the most similar document\n",
    "    return sim[np.argmax(sim)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Test with an exact match string from our corpus\n",
    "test = \"\"\"\n",
    "Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of South Africa. Please pass on the message and make everyone aware.\n",
    "\"\"\"\n",
    "print(getSimilarity(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So an exact match gives us a match of 1.0, which means it's working as expected.  Now we need to start testing how sensitive this is to changing up the words in the test string.  We'll create some variations of the string, and then iterate through them to see how they fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {\n",
    "    'exact': 'Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of South Africa. Please pass on the message and make everyone aware.',\n",
    "    'timechange': 'Please note that there won’t be electricity tomorrow from 08:00- 14:00 through out the whole of South Africa. Please pass on the message and make everyone aware.',\n",
    "    'wordchange': 'Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of Zimbabwe. Please pass on the message and make everyone aware.',\n",
    "    'truncate': 'Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of South Africa. Please pass on the message.',\n",
    "    'truncatechange': 'Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of Zimbabwe. Please pass on the message.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timechange 0.947136805033\n",
      "wordchange 0.922108320412\n",
      "exact 1.0\n",
      "truncatechange 0.864348231688\n",
      "truncate 0.946688357645\n"
     ]
    }
   ],
   "source": [
    "for k, v in tests.items():\n",
    "    print(k, getSimilarity(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity drops away quite quickly if you make big changes (`truncatechange`).  If we wanted to test for exact matches, this would be a good measure, but these messages might get changes up slightly.\n",
    "\n",
    "This is working with unprocessed text.  Let's see if we can get better results by processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timechange 0.947136805033\n",
      "wordchange 0.922108320412\n",
      "exact 1.0\n",
      "truncatechange 0.864348231688\n",
      "truncate 0.946688357645\n"
     ]
    }
   ],
   "source": [
    "# First, try stripping accents\n",
    "tfidf = TfidfVectorizer(strip_accents = 'unicode')\n",
    "# Transform all of our known documents into vector space\n",
    "tfidf_matrix = tfidf.fit_transform(df['quote'].values)\n",
    "\n",
    "for k, v in tests.items():\n",
    "    print(k, getSimilarity(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timechange 0.9894413548\n",
      "wordchange 0.992490253004\n",
      "exact 0.998185613117\n",
      "truncatechange 0.984808925703\n",
      "truncate 0.988944173976\n"
     ]
    }
   ],
   "source": [
    "# Now, work on characters instead of words\n",
    "tfidf = TfidfVectorizer(analyzer = 'char')\n",
    "# Transform all of our known documents into vector space\n",
    "tfidf_matrix = tfidf.fit_transform(df['quote'].values)\n",
    "\n",
    "for k, v in tests.items():\n",
    "    print(k, getSimilarity(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is perhaps too high for our liking and there is not enough spread between hits and misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timechange 0.979670146393\n",
      "wordchange 0.972088116539\n",
      "exact 0.996801513474\n",
      "truncatechange 0.950934466419\n",
      "truncate 0.979433514806\n"
     ]
    }
   ],
   "source": [
    "# Let's add in 2 character n-grams as a middle-ground between characters and words\n",
    "tfidf = TfidfVectorizer(analyzer = 'char',  ngram_range=(1, 2))\n",
    "# Transform all of our known documents into vector space\n",
    "tfidf_matrix = tfidf.fit_transform(df['quote'].values)\n",
    "\n",
    "for k, v in tests.items():\n",
    "    print(k, getSimilarity(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those numbers are still pretty high, what happens if we just put random stuff in there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821485827105\n",
      "So beautiful. Cannot resist not to share.\n",
      "TRUE STORY…PLEASE DO NOT DELETE, RETURN IF YOU CAN’T FORWARD TO AT LEAST ONE PERSON!!!\n",
      "At the prodding of my friends I am writing this story. My name is Mildred Honor. I am a former elementary school Music Teacher from Des Moines, Iowa.\n",
      "\n",
      "\n",
      "\n",
      "     \n",
      "\n",
      "\n",
      "I have always supplemented my income by Teaching Piano Lessons…Something I have done for over 30 years. During those years, I found that Children have many levels of musical ability, and even though I have never had the prodigy, I have taught some very talented students. However, I have also had my share of what I call ‘Musically Challenged Pupils.\n",
      "One such Pupil being Robby. Robby was 11 years old when his Mother (a Single Mom) dropped him off for his first Piano Lesson.\n",
      "I prefer that Students (especially Boys) begin at an earlier age, which I explained to Robby. But Robby said that it had always been his Mother’s Dream to hear him play the Piano, so I took him as a Student.\n",
      "At the end of each weekly Lesson he would always say ‘My Mom’s going to hear me Play someday.’ But to me, it seemed hopeless, he just did not have any Inborn Ability.I only knew his Mother from a distance as she dropped Robby off or waited in her aged Car to pick him up. She always waved and smiled, but never dropped in;\n",
      "Then one day Robby stopped coming for his Lessons. I thought about calling him, but Assumed that because of his lack of Ability he had decided to pursue something else. I was also glad that he had stopped coming. He was a Bad Advertisement for my Teaching!\n",
      "Several Weeks later I mailed a flyer recital to the Students’ homes. To my surprise, Robby (who had received a flyer) asked if he could be in the Recital. I told him that the Recital was for current Pupils and that because he had dropped out, he really did not Qualify.\n",
      "He told me that his Mother had been Sick and Unable to take him to his piano lessons, but that he had been practicing. ‘Please Miss Honor, I’ve just got to Play,’ he insisted. I don’t know what led me to allow him to play in the Recital – perhaps it was his insistence or maybe something inside of me saying that it would be all right;\n",
      "The night of the Recital came and the high school gymnasium was packed with Parents, Relatives and Friends. I put Robby last in the Program, just before I was to come up and thank all the Students and Play a finishing piece. I thought that any damage he might do would come at the end of the Program and I could always salvage his poor performance through my ‘Curtain Closer’.\n",
      "Well, the Recital went off without a Hitch, the Students had been Practicing and it Showed. Then Robby came up on the stage. His Clothes were Wrinkled and his Hair looked as though he had run an egg beater through it. ‘Why wasn’t he dressed up like the other Students?’ I thought. ‘Why didn’t his Mother at least make him Comb his Hair for this Special Night?’\n",
      "Robby pulled out the Piano bench, and I was Surprised when he announced that he had chosen to play Mozart’s Concerto No.21 in C Major. I was not prepared for what I heard next. His fingers were light on the keys, they even danced nimbly on the Ivories. He went from Pianissimo to Fortissimo, from Allegro to Virtuoso; his Suspended Chords that Mozart demands were Magnificent! Never had I heard Mozart played so well by anyone his age.\n",
      "After six and a half minutes, he ended in a Grand Crescendo, and everyone was on their feet in Wild Applause!!! Overcome and in Tears, I ran up on stage and put my arms around Robby in Joy;\n",
      "‘I have never heard you Play like that Robby, how did you do it?’ Through the Microphone Robby explained: ‘Well, Miss Honor, Remember I told you that my Mom was sick? Well, she actually had Cancer and Passed Away this Morning. And well… she was Born Deaf, so tonight was the first time she had ever heard me Play, and I wanted to make it Special.,\n",
      "There wasn’t a Dry Eye in the house that evening. As People from Social Services led Robby from the stage to be placed in to Foster Care, I noticed that even their Eyes were red and Puffy. I thought to myself then how much Richer my Life had been for taking Robby as my Pupil.\n",
      "No, I have never had a Prodigy, but that night I became a Prodigy… of Robby. He was the Teacher and I was the Pupil, for he had taught me the meaning of Perseverance and Love and Believing in Yourself, and may be even taking a chance on someone and you didn’t know why.\n",
      "Robby was Killed years later in the Senseless Bombing of the Alfred P. Murray Federal Building in Oklahoma City in April, 1995.\n",
      "A Footnote to the story. If you are thinking about Forwarding this Message, you are probably wondering which People on your address list aren’t the ‘appropriate’ Ones to receive this type of Message. The Person who sent this to you believes that we can all make a Difference!!!\n",
      "If God didn’t have a Purpose for us, we wouldn’t be here!\n",
      "Live Simply.\n",
      "Love Generously.\n",
      "Care Deeply.\n",
      "Speak Kindly.\n",
      "If you had cried, you are just human. 👍\n"
     ]
    }
   ],
   "source": [
    "test_matrix = tfidf.transform(['Those numbers are still pretty high, what happens if we just put random stuff in there?'])\n",
    "sim = (tfidf_matrix * test_matrix.T).A\n",
    "print(sim[np.argmax(sim)][0])\n",
    "print(df['quote'].values[np.argmax(sim)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.82 feels a bit high for a string that is not even close to anything in the list of documents, especially when we look at what the best match is.\n",
    "\n",
    "What if we take the ngrams and use them on words instead of characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timechange 0.931334741122\n",
      "wordchange 0.937623399575\n",
      "exact 1.0\n",
      "truncatechange 0.863901510335\n",
      "truncate 0.931156472286\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), strip_accents = 'unicode')\n",
    "# Transform all of our known documents into vector space\n",
    "tfidf_matrix = tfidf.fit_transform(df['quote'].values)\n",
    "\n",
    "for k, v in tests.items():\n",
    "    print(k, getSimilarity(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not that much different to using straight words.  This is probably the best option\n",
    "And how does it scale?\n",
    "\n",
    "And when we put in the nonsensical message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0893570257251\n",
      "There is a ‘Floating Rock’ in Jerusalem, floating in air from thousand’s of years. After many researches, still there is no explaination of it.\n"
     ]
    }
   ],
   "source": [
    "test_matrix = tfidf.transform(['Those numbers are still pretty high, what happens if we just put random stuff in there?'])\n",
    "sim = (tfidf_matrix * test_matrix.T).A\n",
    "print(sim[np.argmax(sim)][0])\n",
    "print(df['quote'].values[np.argmax(sim)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is a far better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99999999999999845"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "test = \"\"\"\n",
    "Please note that there won’t be electricity tomorrow from 06:00- 12:00 through out the whole of South Africa. Please pass on the message and make everyone aware.\n",
    "\"\"\"\n",
    "getSimilarity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if instead of 82 messages, we had 20 000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# https://pypi.python.org/pypi/RandomWords/0.1.5\n",
    "from random_words import RandomWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "rw = RandomWords()\n",
    "for i in range(0, 20000):\n",
    "    documents.append(' '.join(rw.random_words(count=random.randint(10, 50))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_tfidf = TfidfVectorizer(ngram_range=(1, 2), strip_accents = 'unicode')\n",
    "scale_tfidf_matrix = scale_tfidf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 9.06 µs\n",
      "0.692516021808\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test = \"\"\"\n",
    "laboratory classrooms camp forearm regulation dates bunches surprise orifices\n",
    "\"\"\"\n",
    "test_matrix = scale_tfidf.transform([test])\n",
    "sim = (scale_tfidf_matrix * test_matrix.T).A\n",
    "print(sim[np.argmax(sim)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 microseconds to check similarity in 20 000 documents.  I'm OK with that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb thread setup rain laboratory classrooms camp forearm regulation dates bunches surprise orifices perforation consideration fatigues input committees'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[np.argmax(sim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide at a lookup level how much leeway we are willing to give for changes within the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "\n",
    "Let's save the vectorizer, the vectorized matrix and the list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../cache/prod_messages.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the vectorizer and the matrix:\n",
    "joblib.dump(tfidf, '../cache/prod_tfidf.pkl')\n",
    "joblib.dump(tfidf_matrix, '../cache/prod_tfidf_matrix.pkl')\n",
    "joblib.dump(df['quote'].values, '../cache/prod_messages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case we want to work with the messages again later, easier format than CSV\n",
    "df.to_feather('../data/messages.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and test\n",
    "\n",
    "When we come to working with this data, we'll want to load it up test that it will work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Load all the bits and test\n",
    "tfidf = joblib.load('../cache/prod_tfidf.pkl')\n",
    "tfidf_matrix = joblib.load('../cache/prod_tfidf_matrix.pkl')\n",
    "messages = joblib.load('../cache/prod_messages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 13.8 µs\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test = \"\"\"\n",
    "Kzn chicken has bird flu. Its not safe to buy chicken - 90000 of chicken is contaminated. Please do not purchase any chicken. Please send to family and friends urgently.\n",
    "\"\"\"\n",
    "test_matrix = tfidf.transform([test])\n",
    "sim = (tfidf_matrix * test_matrix.T).A\n",
    "print(sim[np.argmax(sim)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
